# -*- coding: utf-8 -*-
"""data_collection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/134BpQ_lRe77Nq-dS-wDnl0H4vtrNodyJ
"""

pip install requests biopython

from typing import List, Dict
import requests
from Bio import Entrez
import json
import os


class DataCollector:
    def __init__(self):
        Entrez.email = "shruthiprabakaran20@gmail.com"


    def collect_from_pubmed(self, disease_names, max_results: int = 30):
      """
      Collect data from PubMed for one or multiple diseases
      """

      if isinstance(disease_names, str):
          disease_names = [disease_names]

      all_papers = []

      for disease_name in disease_names:
          try:
              print(f"Searching PubMed for: {disease_name}")
              handle = Entrez.esearch(db="pubmed",
                                    term=f"{disease_name}[Title/Abstract]",
                                    retmax=max_results)
              record = Entrez.read(handle)

              # Get paper IDs
              id_list = record["IdList"]
              print(f"Found {len(id_list)} papers for {disease_name}")

              # Fetch details for each paper
              for paper_id in id_list:
                  try:
                      paper = Entrez.efetch(db="pubmed",
                                          id=paper_id,
                                          rettype="xml")
                      paper_records = Entrez.read(paper)

                      if not paper_records.get('PubmedArticle'):
                          print(f"No PubmedArticle data for paper {paper_id}")
                          continue

                      paper_record = paper_records['PubmedArticle'][0]

                      medline_citation = paper_record.get('MedlineCitation', {})
                      if not medline_citation:
                          print(f"No MedlineCitation for paper {paper_id}")
                          continue

                      article = medline_citation.get('Article', {})
                      if not article:
                          print(f"No Article data for paper {paper_id}")
                          continue

                      authors = []
                      for author in article.get('AuthorList', []):
                          if 'CollectiveName' in author:
                              authors.append(author['CollectiveName'])
                          else:
                              last_name = author.get('LastName', '')
                              fore_name = author.get('ForeName', '')
                              if last_name or fore_name:
                                  authors.append(f"{last_name} {fore_name}".strip())

                      abstract = article.get('Abstract', {})
                      abstract_text = abstract.get('AbstractText', [''])
                      if abstract_text:
                          if isinstance(abstract_text, list):
                              abstract_str = ' '.join(str(text) for text in abstract_text)
                          else:
                              abstract_str = str(abstract_text)
                      else:
                          abstract_str = ''

                      journal = article.get('Journal', {})
                      journal_issue = journal.get('JournalIssue', {})
                      pub_date = journal_issue.get('PubDate', {})
                      pub_date_formatted = {
                          'year': pub_date.get('Year', ''),
                          'month': pub_date.get('Month', ''),
                          'day': pub_date.get('Day', '')
                      }

                      all_papers.append({
                          "source": "pubmed",
                          "paper_id": paper_id,
                          "content": {
                              "title": article.get('ArticleTitle', ''),
                              "abstract": abstract_str,
                              "keywords": article.get('KeywordList', [[]]),
                              "publication_date": pub_date_formatted,
                              "authors": authors,
                              "journal": journal.get('Title', ''),
                              "publication_type": article.get('PublicationTypeList', []),
                              "mesh_terms": [
                                  mesh.get('DescriptorName', '')
                                  for mesh in medline_citation.get('MeshHeadingList', [])
                              ]
                          },
                          "disease": disease_name
                      })

                  except Exception as e:
                      print(f"Error processing paper {paper_id}: {str(e)}")
                      continue

          except Exception as e:
              print(f"Error collecting from PubMed for {disease_name}: {str(e)}")
              continue

      print(f"Total papers collected: {len(all_papers)}")
      return all_papers

    def collect_from_orphadata(self, disease_name: str):
      """
      Collect comprehensive data from Orphadata for one or multiple diseases
      """

      if isinstance(disease_name, str):
          disease_names = [disease_name]
      else:
          disease_names = disease_name

      all_diseases_data = []

      for current_disease in disease_names:
          try:
              current_disease = str(current_disease).strip()
              print(f"Searching for disease: {current_disease}")

              search_url = "https://api.orphadata.com/rd-classification/orphacodes"
              search_response = requests.get(search_url)

              if search_response.status_code != 200:
                  print(f"Search failed for {current_disease}: {search_response.status_code}")
                  continue

              search_data = search_response.json()

              if 'data' in search_data and 'results' in search_data['data']:
                  results = search_data['data']['results']

                  matching_disease = None
                  for disease_result in results:
                      preferred_term = disease_result.get('preferredTerm', '')
                      if not preferred_term:
                          continue

                      search_term = current_disease.lower().strip()
                      preferred_term = preferred_term.lower().strip()

                      if search_term == preferred_term:
                          matching_disease = disease_result
                          break
                      elif search_term in preferred_term:
                          matching_disease = disease_result
                          break

                  if matching_disease:
                      orpha_code = matching_disease['ORPHAcode']
                      print(f"Found disease: {matching_disease['preferredTerm']} (ORPHA:{orpha_code})")

                      comprehensive_data = {}

                      # Get and store basic info
                      basic_info = self._get_basic_info(orpha_code)
                      if basic_info:
                          print(f"Got basic info for ORPHA:{orpha_code}")
                          comprehensive_data.update(basic_info)

                      # Get additional data
                      phenotypes = self._get_clinical_features(orpha_code)
                      if phenotypes:
                          print(f"Got clinical features for ORPHA:{orpha_code}")
                          comprehensive_data["clinical_features"] = phenotypes

                      genes = self._get_genetic_info(orpha_code)
                      if genes:
                          print(f"Got genetic info for ORPHA:{orpha_code}")
                          comprehensive_data["genetic_info"] = genes

                      history = self._get_disease_history(orpha_code)
                      if history:
                          print(f"Got natural history for ORPHA:{orpha_code}")
                          comprehensive_data["natural_history"] = history

                      epidemiology = self._get_epidemiology(orpha_code)
                      if epidemiology:
                          print(f"Got epidemiology data for ORPHA:{orpha_code}")
                          comprehensive_data["epidemiology"] = epidemiology

                      all_diseases_data.append(comprehensive_data)
                  else:
                      print(f"No exact match found for: {current_disease}")
                      print("Available similar diseases:")
                      for disease_result in results[:5]:
                          print(f"- {disease_result['preferredTerm']} (ORPHA:{disease_result['ORPHAcode']})")

          except Exception as e:
              print(f"Error processing disease {current_disease}: {str(e)}")
              continue

      return all_diseases_data

    def _get_basic_info(self, orpha_code: str) -> Dict:
      """Get basic disease information"""
      url = f"https://api.orphadata.com/rd-cross-referencing/orphacodes/{orpha_code}"
      try:
          response = requests.get(url)
          if response.status_code == 200:
              data = response.json()

              if 'data' in data and 'results' in data['data']:
                  results = data['data']['results']

                  basic_info = {
                      "orpha_code": results.get('ORPHAcode'),
                      "preferred_term": results.get('Preferred term'),
                      "synonyms": results.get('Synonym', []),
                      "definition": results.get('SummaryInformation', [{}])[0].get('Definition'),
                      "disorder_group": results.get('DisorderGroup'),
                      "typology": results.get('Typology'),
                      "orphanet_url": results.get('OrphanetURL'),
                      "last_updated": results.get('Date'),
                      "external_references": []
                  }

                  for ref in results.get('ExternalReference', []):
                      basic_info['external_references'].append({
                          "source": ref.get('Source'),
                          "reference": ref.get('Reference'),
                          "relation": ref.get('DisorderMappingRelation'),
                          "validation_status": ref.get('DisorderMappingValidationStatus')
                      })

                  return basic_info

          return {}

      except Exception as e:
          print(f"Error getting basic info: {str(e)}")
          return {}

    def _get_clinical_features(self, orpha_code: str) -> Dict:
      """Get clinical features/phenotypes"""
      url = f"https://api.orphadata.com/rd-phenotypes/orphacodes/{orpha_code}"
      try:
          response = requests.get(url)
          if response.status_code == 200:
              data = response.json()

              if 'data' in data and 'results' in data['data']:
                  results = data['data']['results']
                  disorder = results.get('Disorder', {})

                  clinical_data = {
                      "phenotypes": [],
                      "validation_date": results.get('ValidationDate'),
                      "validation_status": results.get('ValidationStatus')
                  }

                  # Extract phenotype associations
                  for association in disorder.get('HPODisorderAssociation', []):
                      phenotype = {
                          "hpo_id": association.get('HPO', {}).get('HPOId'),
                          "hpo_term": association.get('HPO', {}).get('HPOTerm'),
                          "frequency": association.get('HPOFrequency'),
                          "diagnostic_criteria": association.get('DiagnosticCriteria')
                      }
                      clinical_data["phenotypes"].append(phenotype)

                  return clinical_data

          return {}

      except Exception as e:
          print(f"Error getting clinical features: {str(e)}")
          return {}

    def _get_genetic_info(self, orpha_code: str) -> Dict:
      """Get genetic information"""
      url = f"https://api.orphadata.com/rd-associated-genes/orphacodes/{orpha_code}"
      try:
          response = requests.get(url)
          if response.status_code == 200:
              data = response.json()

              if 'data' in data and 'results' in data['data']:
                  results = data['data']['results']

                  genetic_data = {
                      "genes": [],
                      "last_updated": results.get('Date')
                  }

                  for association in results.get('DisorderGeneAssociation', []):
                      gene = association.get('Gene', {})

                      # Process gene information
                      gene_info = {
                          "symbol": gene.get('Symbol'),
                          "name": gene.get('name'),
                          "type": gene.get('GeneType'),
                          "synonyms": gene.get('Synonym', []),
                          "locus": [
                              {
                                  "position": locus.get('GeneLocus'),
                                  "key": locus.get('LocusKey')
                              }
                              for locus in gene.get('Locus', [])
                          ],
                          "external_references": [
                              {
                                  "source": ref.get('Source'),
                                  "reference": ref.get('Reference')
                              }
                              for ref in gene.get('ExternalReference', [])
                          ],
                          "association_type": association.get('DisorderGeneAssociationType'),
                          "association_status": association.get('DisorderGeneAssociationStatus'),
                          "validation_source": association.get('SourceOfValidation')
                      }

                      genetic_data["genes"].append(gene_info)

                  return genetic_data

          return {}

      except Exception as e:
          print(f"Error getting genetic info: {str(e)}")
          return {}


    def _get_disease_history(self, orpha_code: str) -> Dict:
      """Get natural history information"""
      url = f"https://api.orphadata.com/rd-natural_history/orphacodes/{orpha_code}"
      try:
          response = requests.get(url)
          if response.status_code == 200:
              data = response.json()

              if 'data' in data and 'results' in data['data']:
                  results = data['data']['results']

                  natural_history = {
                      "age_of_onset": results.get('AverageAgeOfOnset', []),
                      "age_of_death": results.get('AverageAgeOfDeath', []),
                      "inheritance": results.get('TypeOfInheritance', []),
                      "last_updated": results.get('Date'),
                      "disease_group": results.get('DisorderGroup'),
                      "disease_type": results.get('Typology'),
                  }

                  return natural_history

          return {}

      except Exception as e:
          print(f"Error getting disease history: {str(e)}")
          return {}

    def _get_epidemiology(self, orpha_code: str) -> Dict:
      """Get epidemiology information"""
      url = f"https://api.orphadata.com/rd-epidemiology/orphacodes/{orpha_code}"
      try:
          response = requests.get(url)
          if response.status_code == 200:
              data = response.json()

              if 'data' in data and 'results' in data['data']:
                  results = data['data']['results']

                  epidemiology_data = {
                      "last_updated": results.get('Date'),
                      "prevalence_data": []
                  }

                  for prevalence in results.get('Prevalence', []):
                      prevalence_info = {
                          "class": prevalence.get('PrevalenceClass'),
                          "geographic_area": prevalence.get('PrevalenceGeographic'),
                          "qualification": prevalence.get('PrevalenceQualification'),
                          "type": prevalence.get('PrevalenceType'),
                          "validation_status": prevalence.get('PrevalenceValidationStatus'),
                          "source": prevalence.get('Source'),
                          "value": prevalence.get('ValMoy')
                      }
                      epidemiology_data["prevalence_data"].append(prevalence_info)

                  return epidemiology_data

          return {}

      except Exception as e:
          print(f"Error getting epidemiology data: {str(e)}")
          return {}

    def collect_all_sources(self, disease_name: str) -> Dict[str, List[Dict]]:
        """Collect data from all sources"""
        return {
            "pubmed": self.collect_from_pubmed(disease_name),
            "orphanet": self.collect_from_orphadata(disease_name)
        }

def merge_disease_data(collected_data: dict):
    """
    Merges Pubmed and Orphanet data entries into a structured dictionary
    """
    merged_data = {}

    def normalize_name(name: str):
        return name.lower().strip()

    name_mapping = {}

    if 'pubmed' in collected_data:
        for paper in collected_data['pubmed']:
            disease_name = paper['disease']
            normalized_name = normalize_name(disease_name)

            if normalized_name not in merged_data:
                merged_data[normalized_name] = {
                    'display_name': disease_name,
                    'papers': [],
                    'disease_info': None
                }

            paper_info = {
                'source': paper['source'],
                'paper_id': paper['paper_id'],
                'title': paper['content']['title'],
                'abstract': paper['content']['abstract'],
                'authors': paper['content']['authors'],
                'publication_date': paper['content']['publication_date'],
                'journal': paper['content']['journal'],
                'keywords': paper['content'].get('keywords', []),
                'mesh_terms': paper['content'].get('mesh_terms', [])
            }

            merged_data[normalized_name]['papers'].append(paper_info)

    if 'orphanet' in collected_data:
        for disease_data in collected_data['orphanet']:
            if not disease_data:
                continue

            disease_info = {
                'orpha_code': disease_data.get('orpha_code', ''),
                'preferred_term': disease_data.get('preferred_term', ''),
                'synonyms': disease_data.get('synonyms', []),
                'definition': disease_data.get('definition', ''),
                'disorder_group': disease_data.get('disorder_group', ''),
                'typology': disease_data.get('typology', ''),
                'orphanet_url': disease_data.get('orphanet_url', ''),
                'last_updated': disease_data.get('last_updated', ''),
                'external_references': disease_data.get('external_references', []),
                'clinical_features': disease_data.get('clinical_features', {}),
                'genetic_info': disease_data.get('genetic_info', {}),
                'natural_history': disease_data.get('natural_history', {}),
                'epidemiology': disease_data.get('epidemiology', {})
            }

            disease_name = disease_data.get('preferred_term', '')
            if disease_name:
                normalized_name = normalize_name(disease_name)

                matched = False
                for existing_name in list(merged_data.keys()):
                    if (normalized_name in existing_name or
                        existing_name in normalized_name):
                        merged_data[existing_name]['disease_info'] = disease_info
                        matched = True
                        break


                if not matched:
                    if normalized_name not in merged_data:
                        merged_data[normalized_name] = {
                            'display_name': disease_name,
                            'papers': [],
                            'disease_info': disease_info
                        }

    print("\nMerged data summary:")
    for normalized_name, data in merged_data.items():
        display_name = data.get('display_name', normalized_name)
        print(f"\nDisease: {display_name}")
        print(f"  Number of papers: {len(data['papers'])}")
        print(f"  Has Orphanet data: {data['disease_info'] is not None}")
        if data['disease_info']:
            print(f"  Orphanet preferred term: {data['disease_info']['preferred_term']}")

    return merged_data

if __name__ == "__main__":
    collector = DataCollector()

    # Collect data for diseases
    diseases = [
          "Alexander Disease",
          "Stoneman syndrome",
          "Batten disease",
          "Angiosarcoma",
          "Botulism",
          "Cystinosis",
          "Kernicterus",
          "Werner Syndrome",
          "Degos Disease"
      ]

    collected_data = collector.collect_all_sources(diseases)

    # Print summary
    for source, data in collected_data.items():
        print(f"{source}: collected {len(data)} records")

# Merge the data
merged_results = merge_disease_data(collected_data)
print(merged_results)

import json
with open('RareDisease_data.json', 'w') as f:
  json.dump(merged_results, f, indent=2)

for data in collected_data.items():
  print(data)